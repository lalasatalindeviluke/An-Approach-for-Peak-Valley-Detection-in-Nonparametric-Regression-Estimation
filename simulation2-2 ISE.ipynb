{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.optimize import minimize\n",
    "from scipy.integrate import quad\n",
    "from findpeaks import findpeaks\n",
    "from quadprog import solve_qp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.auto_peak_valley import Peak_Valley_Simu, IsotonicReg, constrained_splines_reg, comprehensive_csr\n",
    "from module.knot_func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.sin(4*np.pi*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本研究方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_softmax_v2(pv_coordinate: list): # 搞錯的 multi-class logistic reg 作法\n",
    "    pv_coordinate_copy = np.array(pv_coordinate)\n",
    "    output = pv_coordinate_copy / sum(pv_coordinate_copy)\n",
    "    return output # array\n",
    "\n",
    "def reverse_softmax_v2(pv_coordinate_softmax_form, x): # 搞錯的 multi-class logistic reg 作法\n",
    "    pv_coordinate_original_form = 0.12012*(1/pv_coordinate_softmax_form[0])*pv_coordinate_softmax_form\n",
    "    nearest_x = [min(x, key=lambda k: abs(k-j)) for j in pv_coordinate_original_form]\n",
    "    nearest_x_index = [list(x).index(i) for i in nearest_x]\n",
    "    nearest_x_index = [0] + nearest_x_index + [999]\n",
    "    return nearest_x_index\n",
    "\n",
    "def to_softmax_v3(pv_coordinate, x, base=0): # 最終版的 multi-class logistic reg 作法\n",
    "    pv_coordinate_copy = np.hstack((x[0], np.array(pv_coordinate), x[-1]))\n",
    "    pv_coordinate_copy2 = np.diff(pv_coordinate_copy)\n",
    "    log_odds = np.log(pv_coordinate_copy2 / pv_coordinate_copy2[base])\n",
    "    return log_odds\n",
    "\n",
    "def reverse_softmax_v3(pv_coordinate_softmax_form, x): # 最終版的 multi-class logistic reg 作法\n",
    "    # pv_coordinate_original_form = np.exp(pv_coordinate_softmax_form) * 0.24024\n",
    "    # pv_coordinate_original_form = pv_coordinate_original_form.cumsum()[:-1]\n",
    "    pv_coordinate_base_form = 1 / np.sum(np.exp(pv_coordinate_softmax_form))\n",
    "    pv_coordinate_original_form = np.hstack((pv_coordinate_base_form, pv_coordinate_base_form*np.exp(pv_coordinate_softmax_form[1:]))).cumsum()\n",
    "    pv_coordinate_original_form = pv_coordinate_original_form[:-1]\n",
    "    nearest_x = [min(x, key=lambda k: abs(k-j)) for j in pv_coordinate_original_form]\n",
    "    nearest_x_index = [list(x).index(i) for i in nearest_x]\n",
    "    nearest_x_index = [0] + nearest_x_index + [999]\n",
    "    return nearest_x_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef1_list_func(n=200):\n",
    "    coef1_list, knots_list = [], []\n",
    "    for i in range(n):\n",
    "        np.random.seed(i)\n",
    "        x = np.linspace(0, 1, 1000).round(5)\n",
    "        y = f(x) + np.random.normal(scale=0.3, size=(1000,))\n",
    "        multi_peak = Peak_Valley_Simu()\n",
    "        multi_peak.x, multi_peak.y = x, y\n",
    "        multi_peak.auto_peak_points_detection_v3(step=0.02, distance=0.1, iter_scale=1)\n",
    "        multi_peak.auto_valley_points_detection(step=0.02, distance=0.1, iter_scale=1)\n",
    "        pv, pv_index = multi_peak.peak_valley_index()\n",
    "        pv_coordinate_softmax_transform = to_softmax_v3(pv, x)\n",
    "        minimize_result = minimize(multi_peak.isotonic_reg_rss_v3, pv_coordinate_softmax_transform, method=\"Nelder-Mead\", options={\"adaptive\": True}).x\n",
    "        new_pv = x[reverse_softmax_v3(minimize_result, x)]\n",
    "        new_pv_index = reverse_softmax_v3(minimize_result, x)\n",
    "        knots = get_knot(x, y)\n",
    "        compre_csr = comprehensive_csr(x=x, y=y, pv_coordinate=new_pv[1:-1], pv_index=new_pv_index, knots_of_each_part=knots)\n",
    "        try:\n",
    "            coef1_list.append(compre_csr.Solve_QP(deg=3, meq=4))\n",
    "        except ValueError:\n",
    "            print(\"constraints are inconsistent, no solution\")\n",
    "            continue\n",
    "        knots_list.append(compre_csr.comprehensive_knots())\n",
    "    return knots_list, coef1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ISE_list(knots, coef):\n",
    "    ise_list = []\n",
    "    for i, v in enumerate(knots):\n",
    "        def fhat(w):\n",
    "            bx = patsy.bs(x=w, knots=v, degree=3,\n",
    "                        lower_bound=0, upper_bound=1,\n",
    "                        include_intercept=True)\n",
    "            ans = bx @ coef[i]\n",
    "            return ans\n",
    "        def SE(w):\n",
    "            return (fhat(w) - f(w))**2\n",
    "        ise_list.append(quad(SE, 0, 1)[0])\n",
    "    return ise_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knots_list, coef1_list = coef1_list_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ise = ISE_list(knots_list, coef1_list)\n",
    "# np.save(\".\\\\weights\\\\thesis_ise_array\", np.array(ise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005066049690991673"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ise = np.load(\".\\\\weights\\\\thesis_ise_array.npy\")\n",
    "min(ise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scipy 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef2_list_func(n=200):\n",
    "    coef2_list, knots_list = [], []\n",
    "    for i in range(n):\n",
    "        np.random.seed(i)\n",
    "        x = np.linspace(0, 1, 1000).round(5)\n",
    "        y = f(x) + np.random.normal(scale=0.3, size=(1000,))\n",
    "        peaks, _ = find_peaks(y, distance=200, prominence=1, height=1)\n",
    "        valleys, _ = find_peaks(-y, distance=200, prominence=1, height=1)\n",
    "        pv_index2 = np.hstack((peaks, valleys))\n",
    "        knots = get_knot(x, y)\n",
    "        compre_csr = comprehensive_csr(x=x, y=y, pv_coordinate=x[pv_index2], pv_index=pv_index2, knots_of_each_part=knots)\n",
    "        try:\n",
    "            coef2_list.append(compre_csr.Solve_QP(deg=3, meq=4))\n",
    "        except ValueError:\n",
    "            print(\"constraints are inconsistent, no solution\")\n",
    "            continue\n",
    "        knots_list.append(compre_csr.comprehensive_knots())\n",
    "    return knots_list, coef2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constraints are inconsistent, no solution\n"
     ]
    }
   ],
   "source": [
    "# knots_list2, coef_list2 = coef2_list_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ise2 = ISE_list(knots_list2, coef_list2)\n",
    "# np.save(\".\\\\weights\\\\scipy_ise_array\", np.array(ise2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0018332057138386783"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ise2 = np.load(\".\\\\weights\\\\scipy_ise_array.npy\")\n",
    "min(ise2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [findpeaks Peakdetect](https://erdogant.github.io/findpeaks/pages/html/Peakdetect.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef3_list_func(n=200):\n",
    "    coef3_list, knots_list = [], []\n",
    "    for i in range(n):\n",
    "        np.random.seed(i)\n",
    "        x = np.linspace(0, 1, 1000).round(5)\n",
    "        y = f(x) + np.random.normal(scale=0.3, size=(1000,))\n",
    "        fp = findpeaks(method=\"peakdetect\", lookahead=100)\n",
    "        fp_result = fp.fit(y)\n",
    "        pv_index3 = (fp_result[\"df\"][\"peak\"]|fp_result[\"df\"][\"valley\"]).to_numpy()\n",
    "        pv3 = x[pv_index3]\n",
    "        knots = get_knot(x, y)\n",
    "        compre_csr = comprehensive_csr(x=x, y=y, pv_coordinate=pv3[1:-1], pv_index=pv_index3, knots_of_each_part=knots)\n",
    "        try:\n",
    "            coef3_list.append(compre_csr.Solve_QP(deg=3, meq=4))\n",
    "        except ValueError:\n",
    "            print(\"constraints are inconsistent, no solution\")\n",
    "            continue\n",
    "        knots_list.append(compre_csr.comprehensive_knots())\n",
    "    return knots_list, coef3_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knots_list3, coef_list3 = coef3_list_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ise3 = ISE_list(knots_list3, coef_list3)\n",
    "# np.save(\".\\\\weights\\\\fp_ise_array\", np.array(ise3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001442615492572794"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ise3 = np.load(\".\\\\weights\\\\fp_ise_array.npy\")\n",
    "min(ise3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9233e6a22812ba24db2cc046310eb403600c2dcda7f44ff3fec7728043d18b6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
